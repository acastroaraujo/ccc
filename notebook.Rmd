---
title: "notebook"
author: "andrés castro araújo"
date: "3/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")

library(tidyverse)
library(httr)
library(rvest)

outfolder <- "notebook_output/"
if (!dir.exists(outfolder)) dir.create(outfolder)  ## crear una carpeta, si no existe
```

## Descargar nombres y links

```{r}
palabra_clave <- function(q = "y", p = 0) {
  url <- paste0(
    "https://www.corteconstitucional.gov.co/relatoria/query.aspx?anio=/relatoria/",
    "&pg=", p,
    "&buscar=", q
  )
  obj <- httr::GET(url)
  stopifnot(status_code(obj) == 200)
  website <- content(obj)
  
  sentencia <- website %>% 
    html_nodes(".grow a") %>% 
    html_text() %>% 
    str_squish()
  
  link <- website %>% 
    html_nodes(".grow a") %>% 
    html_attr("href")

  tibble(sentencia, link)
}
```

## Gráfico 1.

```{r}
df <- map(0:4, palabra_clave, q = "aborto") %>% 
  bind_rows() %>% 
  distinct()

sentencias <- df %>% 
  distinct(sentencia) %>% 
  mutate(type = str_extract(sentencia, "^(C|SU|T|A)"),
         year = str_extract(sentencia, "\\d{2}$")) %>% 
  mutate(year = as.Date(year, "%y") %>% lubridate::year() %>% as.integer()) 

g <- sentencias %>% 
  count(type, year) %>% 
  ggplot(aes(year, n, fill = type)) + 
  geom_col()

## Default plot
g

## Get my personal theme from https://github.com/acastroaraujo/acathemes
year_seq <- seq(min(sentencias$year), max(sentencias$year), 2)

g + scale_fill_brewer(palette = "RdYlBu") +
    acathemes::theme_custom() + 
    labs(x = NULL, fill = "tipo", title = "Fallos de la Corte Constitucional",
         subtitle = "palabra clave: aborto") +
    scale_x_continuous(breaks = year_seq, labels = year_seq)

ggsave(paste0(outfolder, "fallos_sobre_aborto.png"), 
       device = "png", dpi = "print", height = 4, width = 10)
```


## Extraer citas

Nota. Hay dos sentencias repetidas con links distintos...

```{r}
## Individual Website
extraer_texto <- function(link) { 
  website <- paste0("https://www.corteconstitucional.gov.co", link) %>% 
    read_html() 
  
  output <- website %>% 
    html_nodes(".WordSection1") %>% 
    html_text() %>% 
    str_squish() 
  
  if (is_empty(output)) {
    output <- website %>% 
      html_nodes(".MsoNormal") %>% 
      html_text() %>% 
      str_squish()
  }
  ## nota, buscar una forma de mejorar esto. 
  ## el problema está en que el formato cambia, dependiendo del año
  return(output)
}
```

```{r}
## sólo miramos las sentencias de constitucionalidad: "C"
df <- df %>% 
  filter(str_detect(sentencia, "^C"))
```

```{r, eval=FALSE}
output <- vector("list", length(df$link))
pb <- dplyr::progress_estimated(length(df$link))
for (i in seq_along(output)) {
  output[[i]] <- extraer_texto(df$link[[i]])
  Sys.sleep(runif(1, max = 2))
  pb$tick()$print()
}

citaciones <- output %>% 
  map(paste, collapse = " ") %>% 
  str_extract_all("(S|s)entencia (C|SU|T|A)-\\d+ de \\d{4}") %>% 
  map(str_replace_all, pattern = "(s|S)entencia ([TCSU]{1,2}-\\d+) de \\d{2}(\\d{2})",
      replacement = "\\2-\\3")

texto <- output %>% ## nota, buscar una forma de mejorar esto
  map_chr(paste, collapse = " ")

write_rds(texto, paste0(outfolder, "texto.rds"), compress = "gz")
write_rds(citaciones, paste0(outfolder, "citaciones.rds"), compress = "gz")
```

```{r, fig.height=6, fig.width=10}
citaciones <- read_rds(paste0(outfolder, "citaciones.rds"))
df$citaciones <- citaciones

edge_list <- df %>% 
  unnest(citaciones) %>% 
  count(sentencia, citaciones) %>% 
  rename(from = sentencia, to = citaciones) %>% 
  select(from, to)

library(igraph)
library(ggraph)

g <- edge_list %>% 
  filter(to %in% from) %>%  ## reduce el número de nodos
  igraph::graph_from_data_frame(directed = TRUE) 

g <- decompose(g)[[1]]

igraph::V(g)$out_degree <- igraph::degree(g, mode = "out")
igraph::V(g)$in_degree <- igraph::degree(g, mode = "in")
igraph::V(g)$betweenness <- igraph::betweenness(g, directed = TRUE)
igraph::V(g)$authority_score <- igraph::authority_score(g)$vector
igraph::V(g)$page_rank <- igraph::page_rank(g)$vector
igraph::V(g)$eigen_centrality <- igraph::eigen_centrality(g, directed = TRUE)$vector

g %>% 
  tidygraph::as_tbl_graph() %>% 
  ggraph("kk") +
  geom_edge_link(arrow = arrow(length = unit(1, "mm")),
                 end_cap = circle(3, "mm"), alpha = 0.5) + 
  geom_node_point(aes(color = betweenness, size = in_degree), show.legend = FALSE) + 
  geom_node_label(aes(filter = rank(-betweenness) <= 5, label = name),
                  repel = TRUE, size = 3) +
  theme_graph() + 
  scale_color_gradient(low = "grey90", high = "tomato")
  
ggsave(paste0(outfolder, "red_sentencias_aborto2.png"), 
       device = "png", dpi = "print", height = 6, width = 10)
```

## Texto

```{r, fig.height=5, fig.width=8}
library(tidytext)
df$texto <- read_rds(paste0(outfolder, "texto.rds"))
token_df <- df %>% 
  unnest_tokens(word, texto)

token_df <- token_df %>% 
  anti_join(tibble(word = tm::stopwords("spanish"))) %>% 
  filter(!str_detect(word, "\\d"), nchar(word) > 2) %>% 
  count(sentencia, word, sort = TRUE)

dtm <- cast_dtm(token_df, sentencia, word, n)

library(topicmodels)
sentencias_lda <- topicmodels::LDA(dtm, k = 9, control = list(seed = 1234))
word_probs <- tidy(sentencias_lda, matrix = "beta")
document_probs <- tidy(sentencias_lda, matrix = "gamma")

word_probs %>% 
  group_by(topic) %>% 
  top_n(10, beta) %>% 
  ungroup() %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta)) + 
  geom_col() + 
  facet_wrap(~topic, scales = "free") + 
  coord_flip() +
  scale_x_reordered() +
  acathemes::theme_custom()
  

ggsave(paste0(outfolder, "lda_palabras.png"), 
       device = "png", dpi = "print", height = 5, width = 10)
```

```{r}
document_probs %>% 
  group_by(topic) %>% 
  top_n(2, wt = gamma)
  arrange(gamma) 

document_probs %>% 
  filter(document == "C-355-06") %>% 
  arrange(desc(gamma))
```

```{r}
extract_year <- function(x) {
  str_extract(x, "\\d{2}$") %>% 
    as.Date("%y") %>% 
    lubridate::year() %>% 
    as.integer()
}

document_probs %>% 
  mutate(year = extract_year(document)) %>% 
  ggplot(aes(year, topic, alpha = gamma)) + 
  geom_jitter(height = 0.1) +
  acathemes::theme_super_minimal() +
  scale_y_continuous(breaks = seq(1, 9)) +
  scale_alpha_continuous(range = c(0, 1)) +
  labs(x = NULL, alpha = "posterior\nprobability")

ggsave(paste0(outfolder, "lda_sentencias.png"), 
       device = "png", dpi = "print", height = 5, width = 10)


```

## Pies de página 

```{r}
df$link[[1]]

extraer_pp <- function(link) {
  website <- paste0("https://www.corteconstitucional.gov.co", link) %>% 
    read_html()
  
  website %>% 
    html_nodes(".amplia div div p") %>% 
    html_text() %>% 
    str_squish()
}

extraer_pp(df$link[[100]])
```















